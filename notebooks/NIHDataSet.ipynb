{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NIHDataSet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNRnzZofsxMpryhh8ikOAc+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/veerendra12/CS598-DL4H-Project/blob/main/notebooks/NIHDataSet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import import_ipynb\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from torchvision.transforms import ToPILImage\n",
        "\n",
        "from Utils import get_device\n",
        "from Configuration import CONFIG\n",
        "from LungRegionGenerator import lung_region_generator, lung_region_image_generator\n",
        "from ModelFactory import load_segmentation_model"
      ],
      "metadata": {
        "id": "w4Z-pjqMdm1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_NIH_class_labels():\n",
        "  CLASS_LABELS = CONFIG['CLASS_LABELS']\n",
        "  return CLASS_LABELS"
      ],
      "metadata": {
        "id": "cBRj_j1TeIcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SpseUJ_c5Sq"
      },
      "outputs": [],
      "source": [
        "class NIHImageDataset(Dataset): \n",
        "\n",
        "    def __init__(self, dataset_csv, transform = None, use_lung_region_images = False):\n",
        "        self.transform = transform\n",
        "        \n",
        "        self.df = pd.read_csv(CONFIG['BASE_DIR'] + dataset_csv)\n",
        "        self.df = self.df.set_index(\"Image Index\")\n",
        "        self.use_lung_region_images = use_lung_region_images\n",
        "        if use_lung_region_images:\n",
        "          self.segmentation_model = load_segmentation_model()\n",
        "        self.DEVICE = get_device()\n",
        "        self.CLASS_LABELS = get_NIH_class_labels()\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Args: None\n",
        "        Returns : Length of dataset\n",
        "        \"\"\"\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(os.path.join(CONFIG['IMAGE_DIR'], self.df.index[idx]))\n",
        "        image = image.convert('RGB')\n",
        "\n",
        "        if self.use_lung_region_images:\n",
        "          image_tensor = CONFIG['SEGMENTATION_TRANSOFRM'](image)\n",
        "          image_tensor = image_tensor.to(device=self.DEVICE)\n",
        "          mask = lung_region_generator(image_tensor, self.segmentation_model)\n",
        "          lung_region_image = lung_region_image_generator(image_tensor, mask)\n",
        "\n",
        "          image = ToPILImage()(lung_region_image)      \n",
        "\n",
        "        label_one_hot = np.zeros(len(self.CLASS_LABELS), dtype=int)\n",
        "        for i in range(0, len(self.CLASS_LABELS)):\n",
        "            if(self.df[self.CLASS_LABELS[i].strip()].iloc[idx].astype('int') > 0):\n",
        "                label_one_hot[i] = self.df[self.CLASS_LABELS[i].strip()].iloc[idx].astype('int')\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return (image, label_one_hot)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_NIH_FullCXR_loaders():\n",
        "    print('Using get_NIH_FullCXR_loaders')\n",
        "    batch_size = CONFIG['BATCH_SIZE']\n",
        "    train_dataset = NIHImageDataset(dataset_csv = CONFIG['TRAIN_CSV'], transform = CONFIG['NIH_TRANSFORMS']['train'], use_lung_region_images = False)\n",
        "    validation_dataset = NIHImageDataset(dataset_csv = CONFIG['VALIDATION_CSV'], transform = CONFIG['NIH_TRANSFORMS']['validation'], use_lung_region_images = False)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_dataset, train_loader, validation_dataset, validation_loader"
      ],
      "metadata": {
        "id": "qxNkgnnNiSwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_NIH_LungRegion_loaders():\n",
        "    print('Using get_NIH_LungRegion_loaders')\n",
        "    batch_size = CONFIG['BATCH_SIZE']\n",
        "    train_dataset = NIHImageDataset(dataset_csv = CONFIG['TRAIN_CSV'], transform = CONFIG['NIH_TRANSFORMS']['train'], use_lung_region_images = True)\n",
        "    validation_dataset = NIHImageDataset(dataset_csv = CONFIG['VALIDATION_CSV'], transform = CONFIG['NIH_TRANSFORMS']['validation'], use_lung_region_images = True)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_dataset, train_loader, validation_dataset, validation_loader"
      ],
      "metadata": {
        "id": "fFHq0zriidCk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}